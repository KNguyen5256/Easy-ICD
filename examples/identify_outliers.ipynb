{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f38673",
   "metadata": {},
   "source": [
    "# Identify outliers with Easy-ICD\n",
    "\n",
    "In this notebook we show how we can use a trained outlier detector to identify and mark outliers in a scraped dataset.\n",
    "\n",
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c235588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from easy_icd.utils.datasets import create_dataset\n",
    "from easy_icd.utils.augmentation import RandomImageAugmenter\n",
    "from easy_icd.utils.models import ResNet\n",
    "from easy_icd.outlier_detection.detect_outliers import analyze_data\n",
    "from easy_icd.outlier_removal.remove_outliers import remove_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c18dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'easy_icd.outlier_removal.remove_outliers' from 'F:\\\\College\\\\Penn\\\\Fall 22\\\\CMPSC 445\\\\Final_Project\\\\CMPSC445\\\\easy_icd\\\\src\\\\easy_icd\\\\outlier_removal\\\\remove_outliers.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import easy_icd.outlier_removal.remove_outliers\n",
    "\n",
    "reload(easy_icd.outlier_removal.remove_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6348240",
   "metadata": {},
   "source": [
    "First, we need to create a Dataset object that contains all of the images we want to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc7d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'marine_animals'\n",
    "class_names = ['hammerhead shark', 'orca whale', 'manta ray', 'jellyfish', 'axolotl']\n",
    "one_hot_labels = False\n",
    "scale_images = True\n",
    "\n",
    "ds = create_dataset(img_dir, class_names, one_hot_labels, scale_images)\n",
    "dataloader = DataLoader(ds, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835272c8",
   "metadata": {},
   "source": [
    "Now we create a model using the same architecture as the model we trained as an outlier detector, and load the trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223963d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "num_blocks = [1, 1, 1]\n",
    "in_channels = 3\n",
    "out_channels = [16, 32, 64]\n",
    "linear_sizes = [128, 32]\n",
    "supervised = False\n",
    "\n",
    "model = ResNet(num_layers, num_blocks, in_channels, out_channels, linear_sizes, supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d751bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('marine_animals_model_training/model_state_epoch_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0d23ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing images in class: hammerhead_shark\n",
      "Analyzing images in class: orca_whale\n",
      "Analyzing images in class: manta_ray\n",
      "Analyzing images in class: jellyfish\n",
      "Analyzing images in class: axolotl\n"
     ]
    }
   ],
   "source": [
    "dataset_means_and_stds = [[0.3128, 0.3886, 0.5122], [0.2856, 0.2370, 0.2553]]\n",
    "image_size = (512, 512)\n",
    "num_hardness_loss_samples = 5\n",
    "gpu = False\n",
    "\n",
    "analyze_data(model, img_dir, class_names, dataset_means_and_stds, image_size, num_hardness_loss_samples, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190613cb",
   "metadata": {},
   "source": [
    "Once we have analyzed the images, we can mark the outliers that we detected for exclusion in the cleaned dataset. We do this by first selecting how many images we want to retain the cleaned versions of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59708463",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_images_per_class = [15 for i in range(len(class_names))]\n",
    "\n",
    "remove_outliers(img_dir, class_names, desired_images_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3e94a",
   "metadata": {},
   "source": [
    "Then, constructing the cleaned dataset is as simple as passing the argument `cleaned=True` to the create_dataset function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "132f04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'marine_animals'\n",
    "class_names = ['hammerhead shark', 'orca whale', 'manta ray', 'jellyfish', 'axolotl']\n",
    "one_hot_labels = False\n",
    "scale_images = True\n",
    "cleaned = True\n",
    "\n",
    "ds = create_dataset(img_dir, class_names, one_hot_labels, scale_images, cleaned=cleaned)\n",
    "dataloader = DataLoader(ds, batch_size=4, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
